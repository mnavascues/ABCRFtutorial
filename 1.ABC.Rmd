---
#############################################################
#                                                           #
# Click on "Run Document" in RStudio to run this worksheet. #
#                                                           #
#############################################################
title: "Aproximate Bayesian Computation"
author: "Miguel de Navascu√©s"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library("phyclust", quietly=T)
source("readms.output.R", local =T)
Orange         <- "#E69F00"
Sky_Blue       <- "#56B4E9" 
Bluish_Green   <- "#009E73"
Yellow         <- "#F0E442"
Blue           <- "#0072B2"
Vermillion     <- "#D55E00"
Reddish_Purple <- "#CC79A7"
Black_transparency         <- rgb(  0,  0,  0,100,maxColorValue=255)
Orange_transparency        <- rgb(230,159,  0,100,maxColorValue=255)
SkyBlue_transparency       <- rgb( 86,180,233,100,maxColorValue=255)
BluishGreen_transparency   <- rgb(  0,158,115,100,maxColorValue=255)
Yellow_transparency        <- rgb(240,228, 66,100,maxColorValue=255)
Blue_transparency          <- rgb(  0,114,178,100,maxColorValue=255)
Vermillion_transparency    <- rgb(213, 94,  0,100,maxColorValue=255)
ReddishPurple_transparency <- rgb(204,121,167,100,maxColorValue=255)
```

## Setup

[Colorblind friendly palette](http://jfly.iam.u-tokyo.ac.jp/color/):

```{r color_setup, include=TRUE}
Orange         <- "#E69F00"
Sky_Blue       <- "#56B4E9" 
Bluish_Green   <- "#009E73"
Yellow         <- "#F0E442"
Blue           <- "#0072B2"
Vermillion     <- "#D55E00"
Reddish_Purple <- "#CC79A7"
```



## Approximation 1: Simulation

Approximate Bayesian Computation is a likelihood-free model-based inference approach. The idea behind likelihood-free methods is that the analytical/numerical calculating of the likelihood is substituted by an estimate of the likelihood based on simulations.

### Exercise 1

For the coin toss experiment, estimate the likelihood of $p=0.5$ for $h=4$ and $t=6$ using simulations:

```{r simulation_coin_toss_rbinom, exercise=TRUE}
h = 4; t = 6; p = 0.5
n <- h+t
num_of_sim = _____
h_prime <- rbinom(n=num_of_sim,size=n,prob=p)
_____
```

```{r simulation_coin_toss_rbinom-hint}
h = 4; t = 6; p = 0.5
n <- h+t
num_of_sim = 100
h_prime <- rbinom(n=num_of_sim,size=n,prob=p)
_____(h_prime==h)/_____
```

```{r simulation_coin_toss_rbinom-solution}
h = 4; t = 6; p = 0.5
n <- h+t
num_of_sim = 100
h_prime <- rbinom(n=num_of_sim,size=n,prob=p)
sum(h_prime==h)/num_of_sim
```

The true value (for $p=0.5$, $h=4$ and $t=6$) is `r choose(10, 4) * 0.5^10`. Is the estimate reasonable? How can the estimate be improved?


### Exercise 2

Plot the likelihood profile from using simulation-based estimates of the likelihood. Compare the results with the analytical solution. Why should we bother about a (slower, less accurate) simulation-based solution? For this exercise you have available two functions: `flip_coin_likelihood()` and `flip_coin_likelihood_approx()` (see source code for details).

```{r likelihood_function-setup}
flip_coin_likelihood <- function(p,h,t){
  likelihood <- choose(h+t,h) * p^h * (1-p)^t
  return (list(p=p,l=likelihood))
}
flip_coin_likelihood_approx <- function(p,h,t,num_of_sim){
  likelihood <- array(dim=length(p))
  for (i in seq_along(p)){
    likelihood[i] <- sum(rbinom(n=num_of_sim,size=h+t,prob=p[i])==h)/num_of_sim  
  }
  return (list(p=p,l=likelihood))
}
```


```{r likelihood_function, exercise=TRUE}
h = 4; t = 6; num_of_sim = 1000
p = seq(0,1,0.01)
l_profile_true   <- flip_coin_likelihood(p,h,t)
l_profile_approx <- flip_coin_likelihood_approx(p,h,t,num_of_sim)
plot(x = l_profile_approx$p,
     y = l_profile_approx$l,
     xlab = "p", ylab = "Likelihood", type = "l", col = Bluish_Green, lwd=2)
lines(x = l_profile_true$p,
      y = l_profile_true$l,
      col = Bluish_Green)
```


Posterior probabilities can be also estimated through the use of simulations using the **rejection algorithm**. The following procedure produces a sample from the posterior probability distribution (remember that $P(p|D)\propto L(p|D)P(p)$):

***

**Algorithm 1** Exact rejection sampler

* Given $N$ the number of simulations
* **for** $i=1$ to $N$ **do**
  + Generate $p'\sim\pi(p)$
  + Simulate $D'\sim f(p')$
  + **if** $D'=D$ **then**
    - Accept $p'$
  + **end if**
* **end for** 
* **return** accepted $p'$ 

***

### Exercise 3

Obtain a sample from the posterior probability distribution with the rejection algorithm:

```{r exact_rejection_sampling, exercise=TRUE, exercise.lines=8}
h=4; t=6
a=1; b=1; num_of_sim=1000
p_prime <- _____ # sample from prior distribution (use a beta)
d_prime <- _____ # simulate coin tosses (with binomial)
p_prime_accept <- _____ # keep the values that are equal to the observed data
p_prime_accept
```

```{r exact_rejection_sampling-hint-1}
h=4; t=6
a=1; b=1; num_of_sim=1000
p_prime <- rbeta(num_of_sim,a,b)
d_prime <- _____ # simulate coin tosses (with binomial)
p_prime_accept <- _____ # keep the values that are equal to the observed data
p_prime_accept
```

```{r exact_rejection_sampling-hint-2}
h=4; t=6
a=1; b=1; num_of_sim=1000
p_prime <- rbeta(num_of_sim,a,b)
d_prime <- rbinom(n    = num_of_sim,
                  size = h+t,
                  prob = p_prime)
p_prime_accept <- _____ # keep the values that are equal to the observed data
p_prime_accept
```


```{r exact_rejection_sampling-solution}
h=4; t=6
a=1; b=1; num_of_sim=1000
p_prime <- rbeta(num_of_sim,a,b)
d_prime <- rbinom(n    = num_of_sim,
                  size = h+t,
                  prob = p_prime)
p_prime_accept <- p_prime[which(d_prime==h)]
p_prime_accept
```

### Exercise 4

Use `flip_coin_posterior_approx()` function (see source code for details) to crate a sample from the posterior probability distribution. Create a scatter plot to show the parameter value $p'$ and data $D'$ for all simulations. Highlight simulations that match observed data $D$. Then, use the sample of the posterior probability to plot an estimate of the posterior probability (hint: use `hist()`).

```{r flip_coin_posterior_approx}
flip_coin_posterior_approx <- function(h,t,a,b,num_of_sim){
  p_prime <- rbeta(num_of_sim,a,b)
  d_prime <- rbinom(num_of_sim,h+t,p_prime)
  p_prime_accept <- p_prime[which(d_prime==h)]
  d_prime_accept <- d_prime[which(d_prime==h)]
  return(list(p_prime=p_prime,
              d_prime=d_prime,
              p_prime_accept=p_prime_accept,
              d_prime_accept=d_prime_accept))
}
```


```{r plot_posterior_approx, exercise=TRUE, exercise.lines=20, exercise.setup="flip_coin_posterior_approx"}
h=4;t=6;a=1;b=1;num_of_sim=1000
res <- flip_coin_posterior_approx(h,t,a,b,num_of_sim)

```

```{r plot_posterior_approx-hint}
h=4;t=6;a=1;b=1;num_of_sim=1000
res <- flip_coin_posterior_approx(h,t,a,b,num_of_sim)
plot(res$p_prime,res$d_prime,
     xlab = expression(italic(p)*"'"),
     ylab = expression(italic(D)*"'"))
abline(h = h, col = Reddish_Purple)
points(res$p_prime_accept, res$d_prime_accept, col = Vermillion)

```



```{r plot_posterior_approx-solution}
h=4;t=6;a=1;b=1;num_of_sim=1000
res <- flip_coin_posterior_approx(h,t,a,b,num_of_sim)
plot(res$p_prime,res$d_prime,
     xlab = expression(italic(p)*"'"),
     ylab = expression(italic(D)*"'"))
abline(h = h, col = Reddish_Purple)
points(res$p_prime_accept, res$d_prime_accept, col = Vermillion)
hist(res$p_prime,
     breaks = seq(0,1,0.02),
     col = "grey",
     freq = FALSE,
     ylim = c(0,5),
     main = "", xlab = expression(italic(p)),
     ylab = "probability density")
hist(res$p_prime_accept,
     breaks = seq(0,1,0.02),
     col = Vermillion_transparency,
     freq = FALSE, add = TRUE); box()
lines(seq(0,1,0.001),dbeta(x=seq(0,1,0.001),a+h,b+t),
      col = Vermillion, lwd = 3)
```


### Exercise 5

Get a point estimate and the 95% credibility interval:

```{r coin_toss_credibility_interval, exercise=TRUE, exercise.setup="flip_coin_posterior_approx"}
h=4;t=6;a=1;b=1;num_of_sim=1000
res <- flip_coin_posterior_approx(h,t,a,b,num_of_sim)
p_hat  <- _____
p_95CI <- _____
p_hat; p_95CI
```

```{r coin_toss_credibility_interval-hint}
h=4;t=6;a=1;b=1;num_of_sim=1000
res <- flip_coin_posterior_approx(h,t,a,b,num_of_sim)
p_hat  <- _____(res$p_prime_accept)
p_95CI <- quantile(_____,probs=c(0.025,0.975))
p_hat; p_95CI
```

```{r coin_toss_credibility_interval-solution}
h=4;t=6;a=1;b=1;num_of_sim=1000
res <- flip_coin_posterior_approx(h,t,a,b,num_of_sim)
p_hat  <- median(res$p_prime_accept)
p_95CI <- quantile(res$p_prime_accept,probs=c(0.025,0.975))
p_hat; p_95CI
```

For data $h=4$ and $t=6$, and prior $\mathrm{Beta}(\alpha=1,\beta=1)$ the median is `r qbeta(0.5,1+4,1+6)` and the 95% credibility interval is (`r qbeta(c(0.025,0.975),1+4,1+6)`).


## Approximation 2: Summary Statistics

We are going to consider now population genetics data. We have two data sets of mitochondrial DNA sequences for 50 individuals of two different hermaphrodite species (*actually, it is fake data*). The data is in two files named `dataset1.txt` and `dataset2.txt` in *ms* format.

### Exercise 6

Explore the data. How many polymorphic sites are there? (you can use functions `S()`, `NH()`, `PI()` and `TajimaD()`) How would you apply the rejection algorithm?

```{r explore_genetic_data, exercise=TRUE, exercise.lines=6, exercise.setup = "summary_statistics"}
dataset1 <- read.ms.output(file="/change/to/your/path/dataset1.txt")
dataset2 <- read.ms.output(file="/home/miguel/Work/Teaching/ABCRF tutorial/dataset2.txt")
```

```{r summary_statistics}
S<-function(a) {return(a$segsites)}
NH<-function(a) {
  NH<-vector(length=a$nreps)
  for(i in seq_len(a$nreps)) {
    NH[i] <- nrow(unique(a$gametes[[i]]))
  }
  return(NH)
}
PI<-function(a) {
  PI<-vector(mode='numeric', length=a$nreps)
  for(i in seq_len(a$nreps)) {
    if(a$segsites[i]>0){
      for(j in seq_len(a$segsites[i])) {
         if(a$segsites[i]>1) {
          loc<-sum(a$gametes[[i]][,j])
        } else {
          loc<-sum(a$gametes[[i]])
        }
        PI[i] <- PI[i] + 2*loc*(a$nsam-loc)
      }
    }
  }
  return(PI/(a$nsam*(a$nsam-1)))
}
thetaW<-function(a) {
  a1<-sum(1/(1:(a$nsam-1)))
  return(a$segsites/a1)
}
TajimaD<-function(a) {
  a1<-sum(1/(1:(a$nsam-1)))
  a2<-sum(1/((1:(a$nsam-1))^2))
  b1<-(a$nsam+1)/3/(a$nsam-1)
  b2<-2*(a$nsam^2+a$nsam+3)/(9*a$nsam*(a$nsam-1))
  c1<-b1-1/a1
  c2<-b2-(a$nsam+2)/(a1*a$nsam)+a2/(a1^2)
  temp <- c1/a1*a$segsites + c2/(a1^2+a2)*a$segsites*(a$segsites-1)
  return( (PI(a)-thetaW(a))/sqrt(temp) )
}
```

We could try to apply the same rejection algorithm described above, but the structure of the data is more complex and an exact match would occur rarely in simulations. So we use the second approximation of ABC, instead of the data we use summary statistics ($S$) from the data to classify the simulation as a match to the observation. It is said now that we are approximating the likelihood of $p$ given the summary statistic, $L(p|S)$, rather than the likelihood of $p$ given the data, $L(p|D)$.

***

**Algorithm 2** Exact rejection sampler on summary statistics

* Calculate $S$ from $D$  
* Given $N$ the number of simulations  
* **for** i = 1 to N **do**  
  + Generate $p'\sim\pi(p)$  
  + Simulate $D'\sim f(p')$  
  + Calculate $S'$ from $D'$  
  + **if** $S'=S$ **then**  
    - Accept $p'$  
  + **end if**  
* **end for**  
* **return** accepted $p'$  

***

### Exercise 7

Simulate sequence data with `ms` (from `phyclust` package) using the standard coalescent model (single population of constant size). Simulate with $\theta$ values taken from a log-uniform prior probability distribution (option `"-t tbs"`).

```{r rejection_algortihm_sumstats, exercise=TRUE, exercise.setup = "summary_statistics"}
sample_size = 50
num_of_sim = 10 # use larger number at your own risk /!\
theta_prime <- 10^runif(num_of_sim,min=-1,max=2)
msout <- ms(nsam = sample_size,
            opt = "-t tbs",
            tbs.matrix = cbind(theta_prime))
msout <- read.ms.output(txt=msout)
S_prime  <- S(msout)
PI_prime  <- PI(msout)
```

Simulation can be very time consuming, for the following exercises we will be using a set of simulations which have already been run and summary statistics calculated from them (this is called the **reference table**). This reference table has been produced with the following code:

```{r eval=FALSE, echo=TRUE}
sample_size = 50
num_of_sim = 1000000
theta_prime <- 10^runif(num_of_sim,min=-1,max=2)
msout <- ms(nsam = sample_size,
            opt = "-t tbs",
            tbs.matrix = cbind(theta_prime))
msout <- read.ms.output(txt=msout)
S_prime  <- S(msout)
PI_prime <- PI(msout)
NH_prime <- NH(msout)
TD_prime <- TajimaD(msout)
ref_table <- data.frame(theta=theta_prime,
                        S=S_prime,
                        PI=PI_prime,
                        NH=NH_prime,
                        TD=TD_prime)
saveRDS(ref_table,file="ref_table_1.RDS")
```



### Exercise 8

```{r eval=FALSE, echo=TRUE}
target <- data.frame(S  = c(50,23),
                     PI = c(11.56163,1.354286),
                     row.names = c("dataset1","dataset2"))
```


## Approximation 3: Tolerance

